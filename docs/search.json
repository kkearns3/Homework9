[
  {
    "objectID": "HW9.html",
    "href": "HW9.html",
    "title": "Homework9",
    "section": "",
    "text": "Libraries\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\nWarning: package 'tidymodels' was built under R version 4.4.2\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.1\n✔ recipes      1.1.0     \n\n\nWarning: package 'dials' was built under R version 4.4.2\n\n\nWarning: package 'infer' was built under R version 4.4.2\n\n\nWarning: package 'modeldata' was built under R version 4.4.2\n\n\nWarning: package 'parsnip' was built under R version 4.4.2\n\n\nWarning: package 'recipes' was built under R version 4.4.2\n\n\nWarning: package 'rsample' was built under R version 4.4.2\n\n\nWarning: package 'tune' was built under R version 4.4.2\n\n\nWarning: package 'workflows' was built under R version 4.4.2\n\n\nWarning: package 'workflowsets' was built under R version 4.4.2\n\n\nWarning: package 'yardstick' was built under R version 4.4.2\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use tidymodels_prefer() to resolve common conflicts.\n\n# added for HW 9\nlibrary(baguette)\n\nWarning: package 'baguette' was built under R version 4.4.2\n\n\n\n\nRead in the data from URL, using a solution from a Stack Overflow post to fix the initial error.\n\nbike_data &lt;- read_csv(\"https://www4.stat.ncsu.edu/~online/datasets/SeoulBikeData.csv\",\n                     locale = locale(encoding=\"latin1\"))\n\nRows: 8760 Columns: 14\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (4): Date, Seasons, Holiday, Functioning Day\ndbl (10): Rented Bike Count, Hour, Temperature(°C), Humidity(%), Wind speed ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nbike_data\n\n# A tibble: 8,760 × 14\n   Date       `Rented Bike Count`  Hour `Temperature(°C)` `Humidity(%)`\n   &lt;chr&gt;                    &lt;dbl&gt; &lt;dbl&gt;             &lt;dbl&gt;         &lt;dbl&gt;\n 1 01/12/2017                 254     0              -5.2            37\n 2 01/12/2017                 204     1              -5.5            38\n 3 01/12/2017                 173     2              -6              39\n 4 01/12/2017                 107     3              -6.2            40\n 5 01/12/2017                  78     4              -6              36\n 6 01/12/2017                 100     5              -6.4            37\n 7 01/12/2017                 181     6              -6.6            35\n 8 01/12/2017                 460     7              -7.4            38\n 9 01/12/2017                 930     8              -7.6            37\n10 01/12/2017                 490     9              -6.5            27\n# ℹ 8,750 more rows\n# ℹ 9 more variables: `Wind speed (m/s)` &lt;dbl&gt;, `Visibility (10m)` &lt;dbl&gt;,\n#   `Dew point temperature(°C)` &lt;dbl&gt;, `Solar Radiation (MJ/m2)` &lt;dbl&gt;,\n#   `Rainfall(mm)` &lt;dbl&gt;, `Snowfall (cm)` &lt;dbl&gt;, Seasons &lt;chr&gt;, Holiday &lt;chr&gt;,\n#   `Functioning Day` &lt;chr&gt;\n\n\nRename all columns to make them easier to work with\n\nnames(bike_data) &lt;- c(\"date\", \"rented_bike_count\", \"hour\", \"temperature\", \"humidity\",\n                      \"wind_speed\", \"visibility\", \"dew_point\", \"solar_radiation\",\n                      \"rainfall\", \"snowfall\", \"seasons\", \"holiday\", \"functioning_day\")\n\n\n\n\nLook at structure, see if there are columns that are an unexpected data type based on the values\n\ndate is char, should be changed to date\nhumidity values are stored in a way that makes sense for display (e.g. 37 for 37%), but would need to be divided by 100 if used for computations (unless the computation only involves itself as a variable, e.g. taking the average humidity level)\nseasons, holiday, and functioning_day are character variables that need to be recast as factors\nall other variables are numeric, as expected\n\n\nstr(bike_data)\n\nspc_tbl_ [8,760 × 14] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ date             : chr [1:8760] \"01/12/2017\" \"01/12/2017\" \"01/12/2017\" \"01/12/2017\" ...\n $ rented_bike_count: num [1:8760] 254 204 173 107 78 100 181 460 930 490 ...\n $ hour             : num [1:8760] 0 1 2 3 4 5 6 7 8 9 ...\n $ temperature      : num [1:8760] -5.2 -5.5 -6 -6.2 -6 -6.4 -6.6 -7.4 -7.6 -6.5 ...\n $ humidity         : num [1:8760] 37 38 39 40 36 37 35 38 37 27 ...\n $ wind_speed       : num [1:8760] 2.2 0.8 1 0.9 2.3 1.5 1.3 0.9 1.1 0.5 ...\n $ visibility       : num [1:8760] 2000 2000 2000 2000 2000 ...\n $ dew_point        : num [1:8760] -17.6 -17.6 -17.7 -17.6 -18.6 -18.7 -19.5 -19.3 -19.8 -22.4 ...\n $ solar_radiation  : num [1:8760] 0 0 0 0 0 0 0 0 0.01 0.23 ...\n $ rainfall         : num [1:8760] 0 0 0 0 0 0 0 0 0 0 ...\n $ snowfall         : num [1:8760] 0 0 0 0 0 0 0 0 0 0 ...\n $ seasons          : chr [1:8760] \"Winter\" \"Winter\" \"Winter\" \"Winter\" ...\n $ holiday          : chr [1:8760] \"No Holiday\" \"No Holiday\" \"No Holiday\" \"No Holiday\" ...\n $ functioning_day  : chr [1:8760] \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Date = col_character(),\n  ..   `Rented Bike Count` = col_double(),\n  ..   Hour = col_double(),\n  ..   `Temperature(°C)` = col_double(),\n  ..   `Humidity(%)` = col_double(),\n  ..   `Wind speed (m/s)` = col_double(),\n  ..   `Visibility (10m)` = col_double(),\n  ..   `Dew point temperature(°C)` = col_double(),\n  ..   `Solar Radiation (MJ/m2)` = col_double(),\n  ..   `Rainfall(mm)` = col_double(),\n  ..   `Snowfall (cm)` = col_double(),\n  ..   Seasons = col_character(),\n  ..   Holiday = col_character(),\n  ..   `Functioning Day` = col_character()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\nRecast date - format appears to be dd/mm/yyyy, due to the presence of strings like “15/03/2018”\n\nbike_data &lt;- bike_data |&gt;\n  mutate(date = dmy(date))\n\ncheck the min and max dates in each season to see the order the seasons should be in when that column is recast as factor\n\nbike_data |&gt;\n  group_by(seasons) |&gt;\n  summarize(min_date = min(date),\n            max_date = max(date)) |&gt;\n  arrange(min_date)\n\n# A tibble: 4 × 3\n  seasons min_date   max_date  \n  &lt;chr&gt;   &lt;date&gt;     &lt;date&gt;    \n1 Winter  2017-12-01 2018-02-28\n2 Spring  2018-03-01 2018-05-31\n3 Summer  2018-06-01 2018-08-31\n4 Autumn  2018-09-01 2018-11-30\n\n\nConvert char columns to factors\n\nbike_data &lt;- bike_data |&gt;\n  mutate(seasons = factor(seasons,\n                          levels = c(\"Winter\", \"Spring\", \"Summer\", \"Autumn\")),\n         holiday = as.factor(holiday),\n         functioning_day = as.factor(functioning_day))\n\nbike_data\n\n# A tibble: 8,760 × 14\n   date       rented_bike_count  hour temperature humidity wind_speed visibility\n   &lt;date&gt;                 &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n 1 2017-12-01               254     0        -5.2       37        2.2       2000\n 2 2017-12-01               204     1        -5.5       38        0.8       2000\n 3 2017-12-01               173     2        -6         39        1         2000\n 4 2017-12-01               107     3        -6.2       40        0.9       2000\n 5 2017-12-01                78     4        -6         36        2.3       2000\n 6 2017-12-01               100     5        -6.4       37        1.5       2000\n 7 2017-12-01               181     6        -6.6       35        1.3       2000\n 8 2017-12-01               460     7        -7.4       38        0.9       2000\n 9 2017-12-01               930     8        -7.6       37        1.1       2000\n10 2017-12-01               490     9        -6.5       27        0.5       1928\n# ℹ 8,750 more rows\n# ℹ 7 more variables: dew_point &lt;dbl&gt;, solar_radiation &lt;dbl&gt;, rainfall &lt;dbl&gt;,\n#   snowfall &lt;dbl&gt;, seasons &lt;fct&gt;, holiday &lt;fct&gt;, functioning_day &lt;fct&gt;\n\n\nCheck for missing values\n\ncolSums(is.na(bike_data))\n\n             date rented_bike_count              hour       temperature \n                0                 0                 0                 0 \n         humidity        wind_speed        visibility         dew_point \n                0                 0                 0                 0 \n  solar_radiation          rainfall          snowfall           seasons \n                0                 0                 0                 0 \n          holiday   functioning_day \n                0                 0 \n\n\nBasic summaries for numeric columns\n\npsych::describe(bike_data)\n\nWarning in FUN(newX[, i], ...): no non-missing arguments to min; returning Inf\n\n\nWarning in FUN(newX[, i], ...): no non-missing arguments to max; returning -Inf\n\n\n                  vars    n    mean     sd  median trimmed    mad   min     max\ndate                 1 8760     NaN     NA      NA     NaN     NA   Inf    -Inf\nrented_bike_count    2 8760  704.60 645.00  504.50  612.58 553.75   0.0 3556.00\nhour                 3 8760   11.50   6.92   11.50   11.50   8.90   0.0   23.00\ntemperature          4 8760   12.88  11.94   13.70   13.19  13.94 -17.8   39.40\nhumidity             5 8760   58.23  20.36   57.00   58.02  23.72   0.0   98.00\nwind_speed           6 8760    1.72   1.04    1.50    1.63   1.04   0.0    7.40\nvisibility           7 8760 1436.83 608.30 1698.00 1509.50 447.75  27.0 2000.00\ndew_point            8 8760    4.07  13.06    5.10    4.76  14.38 -30.6   27.20\nsolar_radiation      9 8760    0.57   0.87    0.01    0.38   0.01   0.0    3.52\nrainfall            10 8760    0.15   1.13    0.00    0.00   0.00   0.0   35.00\nsnowfall            11 8760    0.08   0.44    0.00    0.00   0.00   0.0    8.80\nseasons*            12 8760    2.50   1.11    3.00    2.51   1.48   1.0    4.00\nholiday*            13 8760    1.95   0.22    2.00    2.00   0.00   1.0    2.00\nfunctioning_day*    14 8760    1.97   0.18    2.00    2.00   0.00   1.0    2.00\n                    range  skew kurtosis   se\ndate                 -Inf    NA       NA   NA\nrented_bike_count 3556.00  1.15     0.85 6.89\nhour                23.00  0.00    -1.20 0.07\ntemperature         57.20 -0.20    -0.84 0.13\nhumidity            98.00  0.06    -0.80 0.22\nwind_speed           7.40  0.89     0.73 0.01\nvisibility        1973.00 -0.70    -0.96 6.50\ndew_point           57.80 -0.37    -0.76 0.14\nsolar_radiation      3.52  1.50     1.12 0.01\nrainfall            35.00 14.53   284.76 0.01\nsnowfall             8.80  8.44    93.73 0.00\nseasons*             3.00  0.00    -1.35 0.01\nholiday*             1.00 -4.16    15.33 0.00\nfunctioning_day*     1.00 -5.17    24.72 0.00\n\n\nLook at distinct values for the rest of the categorical variables (already did seasons above)\n\nbike_data |&gt;\n  group_by(holiday) |&gt;\n  summarize(count = n())\n\n# A tibble: 2 × 2\n  holiday    count\n  &lt;fct&gt;      &lt;int&gt;\n1 Holiday      432\n2 No Holiday  8328\n\n\n\nbike_data |&gt;\n  group_by(functioning_day) |&gt;\n  summarize(count = n(),\n            total_bikes = sum(rented_bike_count))\n\n# A tibble: 2 × 3\n  functioning_day count total_bikes\n  &lt;fct&gt;           &lt;int&gt;       &lt;dbl&gt;\n1 No                295           0\n2 Yes              8465     6172314\n\n\nNo bikes can be rented on non-functioning days, so those days should be excluded from the model\n\n\n\nProduce summarized data by:\n\ngrouping by date, seasons, and holiday\ntaking the sum of rented_bike_count, rainfall, and snowfall\ntaking the mean of temperature, humidity, wind_speed, visibility, dew_point, solar_radiation\n\n\nbike_rollup &lt;- bike_data |&gt;\n  filter(functioning_day == \"Yes\") |&gt;\n  group_by(date, seasons, holiday) |&gt;\n  summarize(across(c(rented_bike_count, rainfall, snowfall), sum),\n            across(c(temperature, humidity, wind_speed, visibility, \n                     dew_point, solar_radiation), mean))\n\n`summarise()` has grouped output by 'date', 'seasons'. You can override using\nthe `.groups` argument.\n\nbike_rollup\n\n# A tibble: 353 × 12\n# Groups:   date, seasons [353]\n   date       seasons holiday    rented_bike_count rainfall snowfall temperature\n   &lt;date&gt;     &lt;fct&gt;   &lt;fct&gt;                  &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;\n 1 2017-12-01 Winter  No Holiday              9539      0        0       -2.45  \n 2 2017-12-02 Winter  No Holiday              8523      0        0        1.32  \n 3 2017-12-03 Winter  No Holiday              7222      4        0        4.88  \n 4 2017-12-04 Winter  No Holiday              8729      0.1      0       -0.304 \n 5 2017-12-05 Winter  No Holiday              8307      0        0       -4.46  \n 6 2017-12-06 Winter  No Holiday              6669      1.3      8.6      0.0458\n 7 2017-12-07 Winter  No Holiday              8549      0       10.4      1.09  \n 8 2017-12-08 Winter  No Holiday              8032      0        0       -3.82  \n 9 2017-12-09 Winter  No Holiday              7233      0        0       -0.846 \n10 2017-12-10 Winter  No Holiday              3453      4.1     32.5      1.19  \n# ℹ 343 more rows\n# ℹ 5 more variables: humidity &lt;dbl&gt;, wind_speed &lt;dbl&gt;, visibility &lt;dbl&gt;,\n#   dew_point &lt;dbl&gt;, solar_radiation &lt;dbl&gt;\n\n\n\n\n\nRepeat EDA for the new rollup\n\n\n\npsych::describe(bike_rollup)\n\nWarning in FUN(newX[, i], ...): no non-missing arguments to min; returning Inf\n\n\nWarning in FUN(newX[, i], ...): no non-missing arguments to max; returning -Inf\n\n\n                  vars   n     mean      sd   median  trimmed      mad    min\ndate                 1 353      NaN      NA       NA      NaN       NA    Inf\nseasons*             2 353     2.46    1.11     2.00     2.46     1.48   1.00\nholiday*             3 353     1.95    0.21     2.00     2.00     0.00   1.00\nrented_bike_count    4 353 17485.31 9937.16 18563.00 17406.91 13811.90 977.00\nrainfall             5 353     3.58   11.79     0.00     0.62     0.00   0.00\nsnowfall             6 353     1.86    8.80     0.00     0.00     0.00   0.00\ntemperature          7 353    12.78   11.72    13.74    13.07    13.91 -14.74\nhumidity             8 353    58.17   14.87    57.17    57.68    14.89  22.25\nwind_speed           9 353     1.73    0.60     1.66     1.66     0.50   0.66\nvisibility          10 353  1434.01  491.16  1557.75  1482.65   564.44 214.29\ndew_point           11 353     3.95   12.99     4.61     4.54    14.97 -27.75\nsolar_radiation     12 353     0.57    0.32     0.56     0.56     0.41   0.03\n                       max    range  skew kurtosis     se\ndate                  -Inf     -Inf    NA       NA     NA\nseasons*              4.00     3.00  0.03    -1.34   0.06\nholiday*              2.00     1.00 -4.20    15.71   0.01\nrented_bike_count 36149.00 35172.00 -0.04    -1.41 528.90\nrainfall             95.50    95.50  4.88    26.81   0.63\nsnowfall             78.70    78.70  5.83    36.57   0.47\ntemperature          33.74    48.48 -0.21    -0.96   0.62\nhumidity             95.88    73.62  0.26    -0.34   0.79\nwind_speed            4.00     3.34  1.08     1.29   0.03\nvisibility         2000.00  1785.71 -0.62    -0.75  26.14\ndew_point            25.04    52.79 -0.30    -0.88   0.69\nsolar_radiation       1.22     1.19  0.18    -1.09   0.02\n\n\n\nNoting that the mean for rented_bike_count is now a lot higher, which is expected after removing the non-functioning days, and also after taking the sum for all hours for a specific day and then taking the average of that\n\n\nbike_data |&gt;\n  filter(functioning_day == \"Yes\") |&gt;\n  group_by(date) |&gt;\n  summarize(daily_bikes = sum(rented_bike_count)) |&gt;\n  summarize(mean(daily_bikes))\n\n# A tibble: 1 × 1\n  `mean(daily_bikes)`\n                &lt;dbl&gt;\n1              17485.\n\n\n\n\n\n\n\n\ng &lt;- ggplot(bike_rollup, aes(x = rented_bike_count, fill = seasons))\ng + geom_density(alpha = 0.5)\n\n\n\n\n\n\n\n\nI expected to see fewer bikes rented per day during the winter, but the density plot shows it’s much more of a pronounced difference than I thought. Interesting that it rarely broke 10K bikes in the winter, whereas the that would be an unusually low day for summer and autumn. Also kind of interesting that the summer and spring patterns look almost bimodal, so I will be curious to see if there are correlations among the weather-related variables that may explain that.\n\n\n\n\nbike_rollup |&gt;\n  select(where(is.numeric)) |&gt;\n  ungroup() |&gt;\n  select(-date, -seasons) |&gt;\n  cor()\n\nAdding missing grouping variables: `date`, `seasons`\n\n\n                  rented_bike_count    rainfall    snowfall  temperature\nrented_bike_count        1.00000000 -0.23910905 -0.26529110  0.753076732\nrainfall                -0.23910905  1.00000000 -0.02313404  0.144517274\nsnowfall                -0.26529110 -0.02313404  1.00000000 -0.266963662\ntemperature              0.75307673  0.14451727 -0.26696366  1.000000000\nhumidity                 0.03588697  0.52864263  0.06539191  0.404167486\nwind_speed              -0.19288142 -0.10167578  0.02088156 -0.260721792\nvisibility               0.16599375 -0.22199387 -0.10188902  0.002336683\ndew_point                0.65047655  0.26456621 -0.20955286  0.962796255\nsolar_radiation          0.73589290 -0.32270413 -0.23343056  0.550274301\n                     humidity  wind_speed   visibility  dew_point\nrented_bike_count  0.03588697 -0.19288142  0.165993749  0.6504765\nrainfall           0.52864263 -0.10167578 -0.221993866  0.2645662\nsnowfall           0.06539191  0.02088156 -0.101889019 -0.2095529\ntemperature        0.40416749 -0.26072179  0.002336683  0.9627963\nhumidity           1.00000000 -0.23425778 -0.559177334  0.6320473\nwind_speed        -0.23425778  1.00000000  0.206022636 -0.2877032\nvisibility        -0.55917733  0.20602264  1.000000000 -0.1535516\ndew_point          0.63204729 -0.28770322 -0.153551591  1.0000000\nsolar_radiation   -0.27444967  0.09612635  0.271395906  0.3831571\n                  solar_radiation\nrented_bike_count      0.73589290\nrainfall              -0.32270413\nsnowfall              -0.23343056\ntemperature            0.55027430\nhumidity              -0.27444967\nwind_speed             0.09612635\nvisibility             0.27139591\ndew_point              0.38315713\nsolar_radiation        1.00000000\n\n\nDew point, solar radiation, and temperature all seem to have a relatively strong positive correlation to bikes rented. Dew point is also very strongly correlated to temperature, so it makes sense they would both show high correlation to bikes rented (as opposed to only one of them showing a correlation). Solar radiation is interesting, because it is most highly correlated to rented bike count, and only weakly correlated to temperature, and does not show much of a linear relationship to anything else. It seems a bit odd that solar radiation would be related to the rented bike count, while simultaneously showing very little linear relationship to rainfall and snowfall, considering solar radiation may be impacted significantly by precipitation.\n\n\n\nRunning scatter plots on the most highly correlated variables\n\ng &lt;- ggplot(bike_rollup, aes(y = rented_bike_count, x = temperature))\n\ng + geom_point(aes(color = seasons))\n\n\n\n\n\n\n\n\nKind of cool, can see clear distinctions in the rented counts vs temperature between the different seasons\n\ng &lt;- ggplot(bike_rollup, aes(y = rented_bike_count, \n                             x = solar_radiation, \n                             color = seasons))\n\ng + \n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nDefinitely can still see the correlation between solar radiation and bike counts, but there’s less of a clear pattern to the seasons\n\ng &lt;- ggplot(bike_rollup, aes(y = rented_bike_count, x = dew_point, color = seasons))\n\ng + \n  geom_point() + \n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nLooks a lot like the temperature vs rented bikes scatter plot, which kind of makes sense since the dew point is so closely related to the temperature\n\n\n\n\n\n75/25 training to test split\n\n# create the split\nbike_split &lt;- initial_split(bike_rollup, prop = 0.75, strata = seasons)\n\n# create the training and test data sets\nbike_train &lt;- training(bike_split)\nbike_test &lt;- testing(bike_split)\n\n10-fold CV split\n\n# split training set into 10 groups\nbike_10_fold &lt;- vfold_cv(bike_train, 10)\n\n\n\n\n\n\nCreate 3 recipes to preprocess the data for use in MLR models\nRecipe 1\n\ndefine role for date as an ID column so it’s not included in the model, but will be retained in the data set\nadd new factor that determines whether the day of the week for each date falls on the weekend or during the week\nstandardize numeric variables, except for the outcome\n\n\nbike_rec_1 &lt;- recipe(rented_bike_count ~ ., data = bike_train) |&gt;\n  update_role(date, new_role = \"ID\") |&gt;\n  step_date(date, features = c(\"dow\")) |&gt;\n  step_mutate(part_of_week = factor(if_else(date_dow %in% c(\"Sat\", \"Sun\"),\n                                        \"Weekend\",\n                                        \"Weekday\"),\n                                levels = c(\"Weekday\", \"Weekend\"))) |&gt;\n  step_rm(date_dow) |&gt;\n  step_normalize(all_numeric(), -all_outcomes()) |&gt;\n  step_dummy(seasons, holiday, part_of_week)\n  \n\n# view data to make sure it looks okay\nbike_rec_1 |&gt;\n  prep(training = bike_train) |&gt;\n  bake(bike_train)\n\n# A tibble: 263 × 15\n   date       rainfall snowfall temperature humidity wind_speed visibility\n   &lt;date&gt;        &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n 1 2018-09-01   -0.304   -0.236       1.08    0.235     -0.888       0.812\n 2 2018-09-02   -0.304   -0.236       1.04   -0.215     -0.366       1.13 \n 3 2018-09-05   -0.304   -0.236       0.945   0.274      1.40        1.05 \n 4 2018-09-07   -0.175   -0.236       0.802  -0.0574     1.35        0.831\n 5 2018-09-08   -0.304   -0.236       0.762  -0.611     -0.0794      1.11 \n 6 2018-09-09   -0.304   -0.236       0.785  -0.558     -0.844       1.14 \n 7 2018-09-10   -0.304   -0.236       0.869  -0.516     -0.263       1.14 \n 8 2018-09-11   -0.304   -0.236       0.751  -0.659     -0.418       1.14 \n 9 2018-09-12   -0.304   -0.236       0.833  -0.392     -0.690       1.12 \n10 2018-09-13   -0.304   -0.236       0.911   0.308     -0.859       1.11 \n# ℹ 253 more rows\n# ℹ 8 more variables: dew_point &lt;dbl&gt;, solar_radiation &lt;dbl&gt;,\n#   rented_bike_count &lt;dbl&gt;, seasons_Spring &lt;dbl&gt;, seasons_Summer &lt;dbl&gt;,\n#   seasons_Autumn &lt;dbl&gt;, holiday_No.Holiday &lt;dbl&gt;, part_of_week_Weekend &lt;dbl&gt;\n\n\nFormula for recipe 1\n\nbike_rec_1 |&gt;\n  prep(training = bike_train) |&gt;\n  formula()\n\nrented_bike_count ~ rainfall + snowfall + temperature + humidity + \n    wind_speed + visibility + dew_point + solar_radiation + seasons_Spring + \n    seasons_Summer + seasons_Autumn + holiday_No.Holiday + part_of_week_Weekend\n&lt;environment: 0x000002c2a355c3e0&gt;\n\n\nRecipe 2\n\nSame transformations as recipe 1\nAdd interactions to the model formula:\n\nseasons and holiday\nseasons and temp\ntemp and rainfall\n\nOn the first pass, I did not have the step_corr in the preprocessing, but the fit_resamples() generated a warning that stated: “prediction from rank-deficient fit; consider predict(., rankdeficient=”NA”). There were issues with some computations A: x1”.\n\nFirst, I tried step_zv(), since the tidymodel tutorial had stated that if there are dummy variables with low-frequency values that don’t occur in the training data, then it’s possible for some of the downstream functions to generate warnings. That didn’t work.\nFrom other google results, I didn’t find much about the exact warning, but there was a really similar one that apparently can happen when there are variables with really high correlation. Dew point and temperature are very highly correlated, so I decided to use step_cor to address this, and it worked.\n\n\n\nbike_rec_2 &lt;- recipe(rented_bike_count ~ ., data = bike_train) |&gt;\n  update_role(date, new_role = \"ID\") |&gt;\n  step_date(date, features = c(\"dow\")) |&gt;\n  step_mutate(part_of_week = factor(if_else(date_dow %in% c(\"Sat\", \"Sun\"),\n                                        \"Weekend\",\n                                        \"Weekday\"),\n                                levels = c(\"Weekday\", \"Weekend\"))) |&gt;\n  step_rm(date_dow) |&gt;\n  step_normalize(all_numeric(), -all_outcomes()) |&gt;\n  step_dummy(seasons, holiday, part_of_week) |&gt;\n  step_interact(terms = ~ holiday_No.Holiday : starts_with(\"seasons_\") +\n                        temperature : starts_with(\"seasons_\") + \n                        temperature : rainfall) |&gt;\n  #step_zv(all_predictors()) |&gt;\n  step_corr(all_predictors())\n  \nbike_rec_2 |&gt;\n  prep(training = bike_train) |&gt;\n  bake(bike_train)\n\n# A tibble: 263 × 17\n   date       rainfall snowfall temperature humidity wind_speed visibility\n   &lt;date&gt;        &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n 1 2018-09-01   -0.304   -0.236       1.08    0.235     -0.888       0.812\n 2 2018-09-02   -0.304   -0.236       1.04   -0.215     -0.366       1.13 \n 3 2018-09-05   -0.304   -0.236       0.945   0.274      1.40        1.05 \n 4 2018-09-07   -0.175   -0.236       0.802  -0.0574     1.35        0.831\n 5 2018-09-08   -0.304   -0.236       0.762  -0.611     -0.0794      1.11 \n 6 2018-09-09   -0.304   -0.236       0.785  -0.558     -0.844       1.14 \n 7 2018-09-10   -0.304   -0.236       0.869  -0.516     -0.263       1.14 \n 8 2018-09-11   -0.304   -0.236       0.751  -0.659     -0.418       1.14 \n 9 2018-09-12   -0.304   -0.236       0.833  -0.392     -0.690       1.12 \n10 2018-09-13   -0.304   -0.236       0.911   0.308     -0.859       1.11 \n# ℹ 253 more rows\n# ℹ 10 more variables: solar_radiation &lt;dbl&gt;, rented_bike_count &lt;dbl&gt;,\n#   seasons_Spring &lt;dbl&gt;, seasons_Autumn &lt;dbl&gt;, holiday_No.Holiday &lt;dbl&gt;,\n#   part_of_week_Weekend &lt;dbl&gt;, seasons_Spring_x_temperature &lt;dbl&gt;,\n#   seasons_Summer_x_temperature &lt;dbl&gt;, seasons_Autumn_x_temperature &lt;dbl&gt;,\n#   temperature_x_rainfall &lt;dbl&gt;\n\n\nFormula for recipe 2\n\nbike_rec_2 |&gt;\n  prep(training = bike_train) |&gt;\n  formula()\n\nrented_bike_count ~ rainfall + snowfall + temperature + humidity + \n    wind_speed + visibility + solar_radiation + seasons_Spring + \n    seasons_Autumn + holiday_No.Holiday + part_of_week_Weekend + \n    seasons_Spring_x_temperature + seasons_Summer_x_temperature + \n    seasons_Autumn_x_temperature + temperature_x_rainfall\n&lt;environment: 0x000002c2a2380778&gt;\n\n\nRecipe 3\n\nSame transformations and interactions as recipe 2\nAdd quadratic terms for the numeric predictors\n\nNote: On the quadratic step, I initially tried to do step_poly(all_numeric_predictors()), but got an error that said “‘degree’ must be less than number of unique points”. A post on Stack Overflow states this is because there must be columns that don’t have enough unique values. Since the degree is 2, the variables included in step_poly must have at least 3 unique values. All the dummy variables had only 2 unique values. Moving step_poly before step_interact only produced more errors, so I decided to just list out the original predictor variables.\n\nbike_rec_3 &lt;- recipe(rented_bike_count ~ ., data = bike_train) |&gt;\n  update_role(date, new_role = \"ID\") |&gt;\n  step_date(date, features = c(\"dow\")) |&gt;\n  step_mutate(part_of_week = factor(if_else(date_dow %in% c(\"Sat\", \"Sun\"),\n                                        \"Weekend\",\n                                        \"Weekday\"),\n                                levels = c(\"Weekday\", \"Weekend\"))) |&gt;\n  step_rm(date_dow) |&gt;\n  step_normalize(all_numeric(), -all_outcomes()) |&gt;\n  step_dummy(seasons, holiday, part_of_week) |&gt;\n  step_interact(terms = ~ holiday_No.Holiday : starts_with(\"seasons_\") +\n                        temperature : starts_with(\"seasons_\") + \n                        temperature : rainfall) |&gt;\n  # step_poly(all_numeric_predictors())\n  step_poly(rainfall, snowfall, temperature, humidity, wind_speed, visibility,\n            dew_point, solar_radiation) |&gt;\n  step_corr(all_predictors())\n  \nbike_rec_3 |&gt;\n  prep(training = bike_train) |&gt;\n  bake(bike_train)\n\n# A tibble: 263 × 25\n   date       rented_bike_count seasons_Spring seasons_Autumn holiday_No.Holiday\n   &lt;date&gt;                 &lt;dbl&gt;          &lt;dbl&gt;          &lt;dbl&gt;              &lt;dbl&gt;\n 1 2018-09-01             26010              0              1                  1\n 2 2018-09-02             26881              0              1                  1\n 3 2018-09-05             31114              0              1                  1\n 4 2018-09-07             30381              0              1                  1\n 5 2018-09-08             29813              0              1                  1\n 6 2018-09-09             28354              0              1                  1\n 7 2018-09-10             30781              0              1                  1\n 8 2018-09-11             31694              0              1                  1\n 9 2018-09-12             31809              0              1                  1\n10 2018-09-13             30991              0              1                  1\n# ℹ 253 more rows\n# ℹ 20 more variables: part_of_week_Weekend &lt;dbl&gt;,\n#   holiday_No.Holiday_x_seasons_Summer &lt;dbl&gt;,\n#   seasons_Spring_x_temperature &lt;dbl&gt;, seasons_Autumn_x_temperature &lt;dbl&gt;,\n#   temperature_x_rainfall &lt;dbl&gt;, rainfall_poly_1 &lt;dbl&gt;, rainfall_poly_2 &lt;dbl&gt;,\n#   snowfall_poly_1 &lt;dbl&gt;, snowfall_poly_2 &lt;dbl&gt;, temperature_poly_1 &lt;dbl&gt;,\n#   temperature_poly_2 &lt;dbl&gt;, humidity_poly_1 &lt;dbl&gt;, humidity_poly_2 &lt;dbl&gt;, …\n\n\nFormula for recipe 3\n\nbike_rec_3 |&gt;\n  prep(training = bike_train) |&gt;\n  formula()\n\nrented_bike_count ~ seasons_Spring + seasons_Autumn + holiday_No.Holiday + \n    part_of_week_Weekend + holiday_No.Holiday_x_seasons_Summer + \n    seasons_Spring_x_temperature + seasons_Autumn_x_temperature + \n    temperature_x_rainfall + rainfall_poly_1 + rainfall_poly_2 + \n    snowfall_poly_1 + snowfall_poly_2 + temperature_poly_1 + \n    temperature_poly_2 + humidity_poly_1 + humidity_poly_2 + \n    wind_speed_poly_1 + wind_speed_poly_2 + visibility_poly_1 + \n    visibility_poly_2 + dew_point_poly_2 + solar_radiation_poly_1 + \n    solar_radiation_poly_2\n&lt;environment: 0x000002c2a259ca90&gt;\n\n\n\n\n\nUsing a linear model\n\nbike_model &lt;- linear_reg() |&gt;\n  set_engine(\"lm\")\n\n\n\nSet up workflows to use with 10-fold SV to fit a linear model\nRecipe 1\n\nbike_wfl_1 &lt;- workflow() |&gt;\n  add_recipe(bike_rec_1) |&gt;\n  add_model(bike_model)\n\nbike_wfl_1\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_date()\n• step_mutate()\n• step_rm()\n• step_normalize()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n\nRecipe 2\n\nbike_wfl_2 &lt;- workflow() |&gt;\n  add_recipe(bike_rec_2) |&gt;\n  add_model(bike_model)\n\nbike_wfl_2\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n7 Recipe Steps\n\n• step_date()\n• step_mutate()\n• step_rm()\n• step_normalize()\n• step_dummy()\n• step_interact()\n• step_corr()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n\nRecipe 3\n\nbike_wfl_3 &lt;- workflow() |&gt;\n  add_recipe(bike_rec_3) |&gt;\n  add_model(bike_model)\n\nbike_wfl_3\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n8 Recipe Steps\n\n• step_date()\n• step_mutate()\n• step_rm()\n• step_normalize()\n• step_dummy()\n• step_interact()\n• step_poly()\n• step_corr()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n\n\n\n\nHave already set up the 10-fold CV split\nModel 1\n\nbike_CV_fits_1 &lt;- bike_wfl_1 |&gt;\n  fit_resamples(bike_10_fold) \n\nbike_CV_fits_1 |&gt;\n  collect_metrics()\n\n# A tibble: 2 × 6\n  .metric .estimator     mean     n  std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   4090.       10 238.     Preprocessor1_Model1\n2 rsq     standard      0.834    10   0.0186 Preprocessor1_Model1\n\n\nModel 2\n\nbike_CV_fits_2 &lt;- bike_wfl_2 |&gt;\n  fit_resamples(bike_10_fold) \n\nbike_CV_fits_2 |&gt;\n  collect_metrics()\n\n# A tibble: 2 × 6\n  .metric .estimator     mean     n  std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   3806.       10 204.     Preprocessor1_Model1\n2 rsq     standard      0.856    10   0.0158 Preprocessor1_Model1\n\n\nModel 3\n\nbike_CV_fits_3 &lt;- bike_wfl_3 |&gt;\n  fit_resamples(bike_10_fold) \n\nbike_CV_fits_3 |&gt;\n  collect_metrics()\n\n# A tibble: 2 × 6\n  .metric .estimator     mean     n  std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   3375.       10 376.     Preprocessor1_Model1\n2 rsq     standard      0.879    10   0.0322 Preprocessor1_Model1\n\n\n\n\n\n\n\nI ran the previous code multiple times, and the RMSE for each model was variable. Each of the models had the lowest RMSE at least once, but I feel that the second model seems to come in lowest pretty often, so that’s the one I went with.\nFit the best model on the entire training set:\n\nbike_wfl_2 |&gt;\n  #fit(bike_train) |&gt;\n  last_fit(bike_split) |&gt;\n  collect_metrics()\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard    4009.    Preprocessor1_Model1\n2 rsq     standard       0.825 Preprocessor1_Model1\n\n\nFit model on the test data\n\n# workflow for 2nd model\n#lm_fit &lt;- fit(bike_wfl_2, bike_train)\n\n# prediction for bikes rented on the test set\nbike_test_res &lt;- bike_wfl_2 |&gt;\n  fit(bike_train) |&gt;\n  predict(new_data = bike_test)\n\nbike_test_res\n\n# A tibble: 90 × 1\n    .pred\n    &lt;dbl&gt;\n 1  9783.\n 2 10129.\n 3 10781.\n 4  2424.\n 5  1746.\n 6  1398.\n 7 11804.\n 8  3347.\n 9  6300.\n10  4898.\n# ℹ 80 more rows\n\n\nCompute RMSE on the test data (confirm model error given above by last_fit)\n\n# add in the truth values\nbike_test_res &lt;- bike_test_res |&gt;\n  bind_cols(bike_test |&gt; ungroup() |&gt; select(rented_bike_count))\n\n# compare to predicted values\nbike_test_res |&gt;\n  rmse(truth = rented_bike_count, estimate = .pred)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       4009.\n\n\n\n\n\nFit on the entire training set, get coefficient table\n\nbike_wfl_2 |&gt;\n  #last_fit(bike_split) |&gt;\n  fit(bike_train) |&gt;\n  extract_fit_parsnip() |&gt;\n  tidy()\n\n# A tibble: 16 × 5\n   term                         estimate std.error statistic  p.value\n   &lt;chr&gt;                           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)                   20433.      1521.    13.4   3.01e-31\n 2 rainfall                      -3253.       591.    -5.50  9.39e- 8\n 3 snowfall                       -449.       247.    -1.82  7.06e- 2\n 4 temperature                   11732.      1104.    10.6   5.84e-22\n 5 humidity                       1123.       451.     2.49  1.34e- 2\n 6 wind_speed                       55.3      261.     0.212 8.32e- 1\n 7 visibility                      982.       328.     3.00  3.01e- 3\n 8 solar_radiation                4193.       411.    10.2   1.39e-20\n 9 seasons_Spring                -8539.      1302.    -6.56  3.16e-10\n10 seasons_Autumn                -3219.      1343.    -2.40  1.73e- 2\n11 holiday_No.Holiday             5542.      1148.     4.83  2.41e- 6\n12 part_of_week_Weekend          -2226.       508.    -4.38  1.75e- 5\n13 seasons_Spring_x_temperature  -1618.      1335.    -1.21  2.26e- 1\n14 seasons_Summer_x_temperature -14512.      1968.    -7.37  2.50e-12\n15 seasons_Autumn_x_temperature  -7943.      1299.    -6.11  3.75e- 9\n16 temperature_x_rainfall         1202.       654.     1.84  6.73e- 2\n\n\nReally big coefficients, which might be expected since all numeric predictors were standardized, but the outcome was not. To make sure, I am going to plot the predictions over the original data to make sure it looks okay.\nPlot predictions from the test data against the temperature values in that set, since temperature seems to be the most significant predictor\n\n# take predictions already made, and combine with temperature values\nmlm_points &lt;- bike_test_res[\".pred\"] |&gt;\n  bind_cols(bike_test |&gt; ungroup() |&gt; select(temperature))\n\n# plot original data, with the model line overlay\ng &lt;- ggplot(bike_rollup, aes(x = temperature, y = rented_bike_count)) \ng + geom_point(aes(color = seasons)) +\n  geom_smooth(data = mlm_points, aes(x = temperature, y = .pred))\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nHey, it looks pretty good!"
  },
  {
    "objectID": "HW9.html#reading-data",
    "href": "HW9.html#reading-data",
    "title": "Homework9",
    "section": "",
    "text": "Read in the data from URL, using a solution from a Stack Overflow post to fix the initial error.\n\nbike_data &lt;- read_csv(\"https://www4.stat.ncsu.edu/~online/datasets/SeoulBikeData.csv\",\n                     locale = locale(encoding=\"latin1\"))\n\nRows: 8760 Columns: 14\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (4): Date, Seasons, Holiday, Functioning Day\ndbl (10): Rented Bike Count, Hour, Temperature(°C), Humidity(%), Wind speed ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nbike_data\n\n# A tibble: 8,760 × 14\n   Date       `Rented Bike Count`  Hour `Temperature(°C)` `Humidity(%)`\n   &lt;chr&gt;                    &lt;dbl&gt; &lt;dbl&gt;             &lt;dbl&gt;         &lt;dbl&gt;\n 1 01/12/2017                 254     0              -5.2            37\n 2 01/12/2017                 204     1              -5.5            38\n 3 01/12/2017                 173     2              -6              39\n 4 01/12/2017                 107     3              -6.2            40\n 5 01/12/2017                  78     4              -6              36\n 6 01/12/2017                 100     5              -6.4            37\n 7 01/12/2017                 181     6              -6.6            35\n 8 01/12/2017                 460     7              -7.4            38\n 9 01/12/2017                 930     8              -7.6            37\n10 01/12/2017                 490     9              -6.5            27\n# ℹ 8,750 more rows\n# ℹ 9 more variables: `Wind speed (m/s)` &lt;dbl&gt;, `Visibility (10m)` &lt;dbl&gt;,\n#   `Dew point temperature(°C)` &lt;dbl&gt;, `Solar Radiation (MJ/m2)` &lt;dbl&gt;,\n#   `Rainfall(mm)` &lt;dbl&gt;, `Snowfall (cm)` &lt;dbl&gt;, Seasons &lt;chr&gt;, Holiday &lt;chr&gt;,\n#   `Functioning Day` &lt;chr&gt;\n\n\nRename all columns to make them easier to work with\n\nnames(bike_data) &lt;- c(\"date\", \"rented_bike_count\", \"hour\", \"temperature\", \"humidity\",\n                      \"wind_speed\", \"visibility\", \"dew_point\", \"solar_radiation\",\n                      \"rainfall\", \"snowfall\", \"seasons\", \"holiday\", \"functioning_day\")"
  },
  {
    "objectID": "HW9.html#basic-eda",
    "href": "HW9.html#basic-eda",
    "title": "Homework9",
    "section": "",
    "text": "Look at structure, see if there are columns that are an unexpected data type based on the values\n\ndate is char, should be changed to date\nhumidity values are stored in a way that makes sense for display (e.g. 37 for 37%), but would need to be divided by 100 if used for computations (unless the computation only involves itself as a variable, e.g. taking the average humidity level)\nseasons, holiday, and functioning_day are character variables that need to be recast as factors\nall other variables are numeric, as expected\n\n\nstr(bike_data)\n\nspc_tbl_ [8,760 × 14] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ date             : chr [1:8760] \"01/12/2017\" \"01/12/2017\" \"01/12/2017\" \"01/12/2017\" ...\n $ rented_bike_count: num [1:8760] 254 204 173 107 78 100 181 460 930 490 ...\n $ hour             : num [1:8760] 0 1 2 3 4 5 6 7 8 9 ...\n $ temperature      : num [1:8760] -5.2 -5.5 -6 -6.2 -6 -6.4 -6.6 -7.4 -7.6 -6.5 ...\n $ humidity         : num [1:8760] 37 38 39 40 36 37 35 38 37 27 ...\n $ wind_speed       : num [1:8760] 2.2 0.8 1 0.9 2.3 1.5 1.3 0.9 1.1 0.5 ...\n $ visibility       : num [1:8760] 2000 2000 2000 2000 2000 ...\n $ dew_point        : num [1:8760] -17.6 -17.6 -17.7 -17.6 -18.6 -18.7 -19.5 -19.3 -19.8 -22.4 ...\n $ solar_radiation  : num [1:8760] 0 0 0 0 0 0 0 0 0.01 0.23 ...\n $ rainfall         : num [1:8760] 0 0 0 0 0 0 0 0 0 0 ...\n $ snowfall         : num [1:8760] 0 0 0 0 0 0 0 0 0 0 ...\n $ seasons          : chr [1:8760] \"Winter\" \"Winter\" \"Winter\" \"Winter\" ...\n $ holiday          : chr [1:8760] \"No Holiday\" \"No Holiday\" \"No Holiday\" \"No Holiday\" ...\n $ functioning_day  : chr [1:8760] \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Date = col_character(),\n  ..   `Rented Bike Count` = col_double(),\n  ..   Hour = col_double(),\n  ..   `Temperature(°C)` = col_double(),\n  ..   `Humidity(%)` = col_double(),\n  ..   `Wind speed (m/s)` = col_double(),\n  ..   `Visibility (10m)` = col_double(),\n  ..   `Dew point temperature(°C)` = col_double(),\n  ..   `Solar Radiation (MJ/m2)` = col_double(),\n  ..   `Rainfall(mm)` = col_double(),\n  ..   `Snowfall (cm)` = col_double(),\n  ..   Seasons = col_character(),\n  ..   Holiday = col_character(),\n  ..   `Functioning Day` = col_character()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\nRecast date - format appears to be dd/mm/yyyy, due to the presence of strings like “15/03/2018”\n\nbike_data &lt;- bike_data |&gt;\n  mutate(date = dmy(date))\n\ncheck the min and max dates in each season to see the order the seasons should be in when that column is recast as factor\n\nbike_data |&gt;\n  group_by(seasons) |&gt;\n  summarize(min_date = min(date),\n            max_date = max(date)) |&gt;\n  arrange(min_date)\n\n# A tibble: 4 × 3\n  seasons min_date   max_date  \n  &lt;chr&gt;   &lt;date&gt;     &lt;date&gt;    \n1 Winter  2017-12-01 2018-02-28\n2 Spring  2018-03-01 2018-05-31\n3 Summer  2018-06-01 2018-08-31\n4 Autumn  2018-09-01 2018-11-30\n\n\nConvert char columns to factors\n\nbike_data &lt;- bike_data |&gt;\n  mutate(seasons = factor(seasons,\n                          levels = c(\"Winter\", \"Spring\", \"Summer\", \"Autumn\")),\n         holiday = as.factor(holiday),\n         functioning_day = as.factor(functioning_day))\n\nbike_data\n\n# A tibble: 8,760 × 14\n   date       rented_bike_count  hour temperature humidity wind_speed visibility\n   &lt;date&gt;                 &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n 1 2017-12-01               254     0        -5.2       37        2.2       2000\n 2 2017-12-01               204     1        -5.5       38        0.8       2000\n 3 2017-12-01               173     2        -6         39        1         2000\n 4 2017-12-01               107     3        -6.2       40        0.9       2000\n 5 2017-12-01                78     4        -6         36        2.3       2000\n 6 2017-12-01               100     5        -6.4       37        1.5       2000\n 7 2017-12-01               181     6        -6.6       35        1.3       2000\n 8 2017-12-01               460     7        -7.4       38        0.9       2000\n 9 2017-12-01               930     8        -7.6       37        1.1       2000\n10 2017-12-01               490     9        -6.5       27        0.5       1928\n# ℹ 8,750 more rows\n# ℹ 7 more variables: dew_point &lt;dbl&gt;, solar_radiation &lt;dbl&gt;, rainfall &lt;dbl&gt;,\n#   snowfall &lt;dbl&gt;, seasons &lt;fct&gt;, holiday &lt;fct&gt;, functioning_day &lt;fct&gt;\n\n\nCheck for missing values\n\ncolSums(is.na(bike_data))\n\n             date rented_bike_count              hour       temperature \n                0                 0                 0                 0 \n         humidity        wind_speed        visibility         dew_point \n                0                 0                 0                 0 \n  solar_radiation          rainfall          snowfall           seasons \n                0                 0                 0                 0 \n          holiday   functioning_day \n                0                 0 \n\n\nBasic summaries for numeric columns\n\npsych::describe(bike_data)\n\nWarning in FUN(newX[, i], ...): no non-missing arguments to min; returning Inf\n\n\nWarning in FUN(newX[, i], ...): no non-missing arguments to max; returning -Inf\n\n\n                  vars    n    mean     sd  median trimmed    mad   min     max\ndate                 1 8760     NaN     NA      NA     NaN     NA   Inf    -Inf\nrented_bike_count    2 8760  704.60 645.00  504.50  612.58 553.75   0.0 3556.00\nhour                 3 8760   11.50   6.92   11.50   11.50   8.90   0.0   23.00\ntemperature          4 8760   12.88  11.94   13.70   13.19  13.94 -17.8   39.40\nhumidity             5 8760   58.23  20.36   57.00   58.02  23.72   0.0   98.00\nwind_speed           6 8760    1.72   1.04    1.50    1.63   1.04   0.0    7.40\nvisibility           7 8760 1436.83 608.30 1698.00 1509.50 447.75  27.0 2000.00\ndew_point            8 8760    4.07  13.06    5.10    4.76  14.38 -30.6   27.20\nsolar_radiation      9 8760    0.57   0.87    0.01    0.38   0.01   0.0    3.52\nrainfall            10 8760    0.15   1.13    0.00    0.00   0.00   0.0   35.00\nsnowfall            11 8760    0.08   0.44    0.00    0.00   0.00   0.0    8.80\nseasons*            12 8760    2.50   1.11    3.00    2.51   1.48   1.0    4.00\nholiday*            13 8760    1.95   0.22    2.00    2.00   0.00   1.0    2.00\nfunctioning_day*    14 8760    1.97   0.18    2.00    2.00   0.00   1.0    2.00\n                    range  skew kurtosis   se\ndate                 -Inf    NA       NA   NA\nrented_bike_count 3556.00  1.15     0.85 6.89\nhour                23.00  0.00    -1.20 0.07\ntemperature         57.20 -0.20    -0.84 0.13\nhumidity            98.00  0.06    -0.80 0.22\nwind_speed           7.40  0.89     0.73 0.01\nvisibility        1973.00 -0.70    -0.96 6.50\ndew_point           57.80 -0.37    -0.76 0.14\nsolar_radiation      3.52  1.50     1.12 0.01\nrainfall            35.00 14.53   284.76 0.01\nsnowfall             8.80  8.44    93.73 0.00\nseasons*             3.00  0.00    -1.35 0.01\nholiday*             1.00 -4.16    15.33 0.00\nfunctioning_day*     1.00 -5.17    24.72 0.00\n\n\nLook at distinct values for the rest of the categorical variables (already did seasons above)\n\nbike_data |&gt;\n  group_by(holiday) |&gt;\n  summarize(count = n())\n\n# A tibble: 2 × 2\n  holiday    count\n  &lt;fct&gt;      &lt;int&gt;\n1 Holiday      432\n2 No Holiday  8328\n\n\n\nbike_data |&gt;\n  group_by(functioning_day) |&gt;\n  summarize(count = n(),\n            total_bikes = sum(rented_bike_count))\n\n# A tibble: 2 × 3\n  functioning_day count total_bikes\n  &lt;fct&gt;           &lt;int&gt;       &lt;dbl&gt;\n1 No                295           0\n2 Yes              8465     6172314\n\n\nNo bikes can be rented on non-functioning days, so those days should be excluded from the model"
  },
  {
    "objectID": "HW9.html#data-rollup",
    "href": "HW9.html#data-rollup",
    "title": "Homework9",
    "section": "",
    "text": "Produce summarized data by:\n\ngrouping by date, seasons, and holiday\ntaking the sum of rented_bike_count, rainfall, and snowfall\ntaking the mean of temperature, humidity, wind_speed, visibility, dew_point, solar_radiation\n\n\nbike_rollup &lt;- bike_data |&gt;\n  filter(functioning_day == \"Yes\") |&gt;\n  group_by(date, seasons, holiday) |&gt;\n  summarize(across(c(rented_bike_count, rainfall, snowfall), sum),\n            across(c(temperature, humidity, wind_speed, visibility, \n                     dew_point, solar_radiation), mean))\n\n`summarise()` has grouped output by 'date', 'seasons'. You can override using\nthe `.groups` argument.\n\nbike_rollup\n\n# A tibble: 353 × 12\n# Groups:   date, seasons [353]\n   date       seasons holiday    rented_bike_count rainfall snowfall temperature\n   &lt;date&gt;     &lt;fct&gt;   &lt;fct&gt;                  &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;\n 1 2017-12-01 Winter  No Holiday              9539      0        0       -2.45  \n 2 2017-12-02 Winter  No Holiday              8523      0        0        1.32  \n 3 2017-12-03 Winter  No Holiday              7222      4        0        4.88  \n 4 2017-12-04 Winter  No Holiday              8729      0.1      0       -0.304 \n 5 2017-12-05 Winter  No Holiday              8307      0        0       -4.46  \n 6 2017-12-06 Winter  No Holiday              6669      1.3      8.6      0.0458\n 7 2017-12-07 Winter  No Holiday              8549      0       10.4      1.09  \n 8 2017-12-08 Winter  No Holiday              8032      0        0       -3.82  \n 9 2017-12-09 Winter  No Holiday              7233      0        0       -0.846 \n10 2017-12-10 Winter  No Holiday              3453      4.1     32.5      1.19  \n# ℹ 343 more rows\n# ℹ 5 more variables: humidity &lt;dbl&gt;, wind_speed &lt;dbl&gt;, visibility &lt;dbl&gt;,\n#   dew_point &lt;dbl&gt;, solar_radiation &lt;dbl&gt;"
  },
  {
    "objectID": "HW9.html#eda-part-2",
    "href": "HW9.html#eda-part-2",
    "title": "Homework9",
    "section": "",
    "text": "Repeat EDA for the new rollup\n\n\n\npsych::describe(bike_rollup)\n\nWarning in FUN(newX[, i], ...): no non-missing arguments to min; returning Inf\n\n\nWarning in FUN(newX[, i], ...): no non-missing arguments to max; returning -Inf\n\n\n                  vars   n     mean      sd   median  trimmed      mad    min\ndate                 1 353      NaN      NA       NA      NaN       NA    Inf\nseasons*             2 353     2.46    1.11     2.00     2.46     1.48   1.00\nholiday*             3 353     1.95    0.21     2.00     2.00     0.00   1.00\nrented_bike_count    4 353 17485.31 9937.16 18563.00 17406.91 13811.90 977.00\nrainfall             5 353     3.58   11.79     0.00     0.62     0.00   0.00\nsnowfall             6 353     1.86    8.80     0.00     0.00     0.00   0.00\ntemperature          7 353    12.78   11.72    13.74    13.07    13.91 -14.74\nhumidity             8 353    58.17   14.87    57.17    57.68    14.89  22.25\nwind_speed           9 353     1.73    0.60     1.66     1.66     0.50   0.66\nvisibility          10 353  1434.01  491.16  1557.75  1482.65   564.44 214.29\ndew_point           11 353     3.95   12.99     4.61     4.54    14.97 -27.75\nsolar_radiation     12 353     0.57    0.32     0.56     0.56     0.41   0.03\n                       max    range  skew kurtosis     se\ndate                  -Inf     -Inf    NA       NA     NA\nseasons*              4.00     3.00  0.03    -1.34   0.06\nholiday*              2.00     1.00 -4.20    15.71   0.01\nrented_bike_count 36149.00 35172.00 -0.04    -1.41 528.90\nrainfall             95.50    95.50  4.88    26.81   0.63\nsnowfall             78.70    78.70  5.83    36.57   0.47\ntemperature          33.74    48.48 -0.21    -0.96   0.62\nhumidity             95.88    73.62  0.26    -0.34   0.79\nwind_speed            4.00     3.34  1.08     1.29   0.03\nvisibility         2000.00  1785.71 -0.62    -0.75  26.14\ndew_point            25.04    52.79 -0.30    -0.88   0.69\nsolar_radiation       1.22     1.19  0.18    -1.09   0.02\n\n\n\nNoting that the mean for rented_bike_count is now a lot higher, which is expected after removing the non-functioning days, and also after taking the sum for all hours for a specific day and then taking the average of that\n\n\nbike_data |&gt;\n  filter(functioning_day == \"Yes\") |&gt;\n  group_by(date) |&gt;\n  summarize(daily_bikes = sum(rented_bike_count)) |&gt;\n  summarize(mean(daily_bikes))\n\n# A tibble: 1 × 1\n  `mean(daily_bikes)`\n                &lt;dbl&gt;\n1              17485.\n\n\n\n\n\n\n\n\ng &lt;- ggplot(bike_rollup, aes(x = rented_bike_count, fill = seasons))\ng + geom_density(alpha = 0.5)\n\n\n\n\n\n\n\n\nI expected to see fewer bikes rented per day during the winter, but the density plot shows it’s much more of a pronounced difference than I thought. Interesting that it rarely broke 10K bikes in the winter, whereas the that would be an unusually low day for summer and autumn. Also kind of interesting that the summer and spring patterns look almost bimodal, so I will be curious to see if there are correlations among the weather-related variables that may explain that.\n\n\n\n\nbike_rollup |&gt;\n  select(where(is.numeric)) |&gt;\n  ungroup() |&gt;\n  select(-date, -seasons) |&gt;\n  cor()\n\nAdding missing grouping variables: `date`, `seasons`\n\n\n                  rented_bike_count    rainfall    snowfall  temperature\nrented_bike_count        1.00000000 -0.23910905 -0.26529110  0.753076732\nrainfall                -0.23910905  1.00000000 -0.02313404  0.144517274\nsnowfall                -0.26529110 -0.02313404  1.00000000 -0.266963662\ntemperature              0.75307673  0.14451727 -0.26696366  1.000000000\nhumidity                 0.03588697  0.52864263  0.06539191  0.404167486\nwind_speed              -0.19288142 -0.10167578  0.02088156 -0.260721792\nvisibility               0.16599375 -0.22199387 -0.10188902  0.002336683\ndew_point                0.65047655  0.26456621 -0.20955286  0.962796255\nsolar_radiation          0.73589290 -0.32270413 -0.23343056  0.550274301\n                     humidity  wind_speed   visibility  dew_point\nrented_bike_count  0.03588697 -0.19288142  0.165993749  0.6504765\nrainfall           0.52864263 -0.10167578 -0.221993866  0.2645662\nsnowfall           0.06539191  0.02088156 -0.101889019 -0.2095529\ntemperature        0.40416749 -0.26072179  0.002336683  0.9627963\nhumidity           1.00000000 -0.23425778 -0.559177334  0.6320473\nwind_speed        -0.23425778  1.00000000  0.206022636 -0.2877032\nvisibility        -0.55917733  0.20602264  1.000000000 -0.1535516\ndew_point          0.63204729 -0.28770322 -0.153551591  1.0000000\nsolar_radiation   -0.27444967  0.09612635  0.271395906  0.3831571\n                  solar_radiation\nrented_bike_count      0.73589290\nrainfall              -0.32270413\nsnowfall              -0.23343056\ntemperature            0.55027430\nhumidity              -0.27444967\nwind_speed             0.09612635\nvisibility             0.27139591\ndew_point              0.38315713\nsolar_radiation        1.00000000\n\n\nDew point, solar radiation, and temperature all seem to have a relatively strong positive correlation to bikes rented. Dew point is also very strongly correlated to temperature, so it makes sense they would both show high correlation to bikes rented (as opposed to only one of them showing a correlation). Solar radiation is interesting, because it is most highly correlated to rented bike count, and only weakly correlated to temperature, and does not show much of a linear relationship to anything else. It seems a bit odd that solar radiation would be related to the rented bike count, while simultaneously showing very little linear relationship to rainfall and snowfall, considering solar radiation may be impacted significantly by precipitation.\n\n\n\nRunning scatter plots on the most highly correlated variables\n\ng &lt;- ggplot(bike_rollup, aes(y = rented_bike_count, x = temperature))\n\ng + geom_point(aes(color = seasons))\n\n\n\n\n\n\n\n\nKind of cool, can see clear distinctions in the rented counts vs temperature between the different seasons\n\ng &lt;- ggplot(bike_rollup, aes(y = rented_bike_count, \n                             x = solar_radiation, \n                             color = seasons))\n\ng + \n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nDefinitely can still see the correlation between solar radiation and bike counts, but there’s less of a clear pattern to the seasons\n\ng &lt;- ggplot(bike_rollup, aes(y = rented_bike_count, x = dew_point, color = seasons))\n\ng + \n  geom_point() + \n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nLooks a lot like the temperature vs rented bikes scatter plot, which kind of makes sense since the dew point is so closely related to the temperature"
  },
  {
    "objectID": "HW9.html#split-the-data",
    "href": "HW9.html#split-the-data",
    "title": "Homework9",
    "section": "",
    "text": "75/25 training to test split\n\n# create the split\nbike_split &lt;- initial_split(bike_rollup, prop = 0.75, strata = seasons)\n\n# create the training and test data sets\nbike_train &lt;- training(bike_split)\nbike_test &lt;- testing(bike_split)\n\n10-fold CV split\n\n# split training set into 10 groups\nbike_10_fold &lt;- vfold_cv(bike_train, 10)"
  },
  {
    "objectID": "HW9.html#fitting-mlr-models",
    "href": "HW9.html#fitting-mlr-models",
    "title": "Homework9",
    "section": "",
    "text": "Create 3 recipes to preprocess the data for use in MLR models\nRecipe 1\n\ndefine role for date as an ID column so it’s not included in the model, but will be retained in the data set\nadd new factor that determines whether the day of the week for each date falls on the weekend or during the week\nstandardize numeric variables, except for the outcome\n\n\nbike_rec_1 &lt;- recipe(rented_bike_count ~ ., data = bike_train) |&gt;\n  update_role(date, new_role = \"ID\") |&gt;\n  step_date(date, features = c(\"dow\")) |&gt;\n  step_mutate(part_of_week = factor(if_else(date_dow %in% c(\"Sat\", \"Sun\"),\n                                        \"Weekend\",\n                                        \"Weekday\"),\n                                levels = c(\"Weekday\", \"Weekend\"))) |&gt;\n  step_rm(date_dow) |&gt;\n  step_normalize(all_numeric(), -all_outcomes()) |&gt;\n  step_dummy(seasons, holiday, part_of_week)\n  \n\n# view data to make sure it looks okay\nbike_rec_1 |&gt;\n  prep(training = bike_train) |&gt;\n  bake(bike_train)\n\n# A tibble: 263 × 15\n   date       rainfall snowfall temperature humidity wind_speed visibility\n   &lt;date&gt;        &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n 1 2018-09-01   -0.304   -0.236       1.08    0.235     -0.888       0.812\n 2 2018-09-02   -0.304   -0.236       1.04   -0.215     -0.366       1.13 \n 3 2018-09-05   -0.304   -0.236       0.945   0.274      1.40        1.05 \n 4 2018-09-07   -0.175   -0.236       0.802  -0.0574     1.35        0.831\n 5 2018-09-08   -0.304   -0.236       0.762  -0.611     -0.0794      1.11 \n 6 2018-09-09   -0.304   -0.236       0.785  -0.558     -0.844       1.14 \n 7 2018-09-10   -0.304   -0.236       0.869  -0.516     -0.263       1.14 \n 8 2018-09-11   -0.304   -0.236       0.751  -0.659     -0.418       1.14 \n 9 2018-09-12   -0.304   -0.236       0.833  -0.392     -0.690       1.12 \n10 2018-09-13   -0.304   -0.236       0.911   0.308     -0.859       1.11 \n# ℹ 253 more rows\n# ℹ 8 more variables: dew_point &lt;dbl&gt;, solar_radiation &lt;dbl&gt;,\n#   rented_bike_count &lt;dbl&gt;, seasons_Spring &lt;dbl&gt;, seasons_Summer &lt;dbl&gt;,\n#   seasons_Autumn &lt;dbl&gt;, holiday_No.Holiday &lt;dbl&gt;, part_of_week_Weekend &lt;dbl&gt;\n\n\nFormula for recipe 1\n\nbike_rec_1 |&gt;\n  prep(training = bike_train) |&gt;\n  formula()\n\nrented_bike_count ~ rainfall + snowfall + temperature + humidity + \n    wind_speed + visibility + dew_point + solar_radiation + seasons_Spring + \n    seasons_Summer + seasons_Autumn + holiday_No.Holiday + part_of_week_Weekend\n&lt;environment: 0x000002c2a355c3e0&gt;\n\n\nRecipe 2\n\nSame transformations as recipe 1\nAdd interactions to the model formula:\n\nseasons and holiday\nseasons and temp\ntemp and rainfall\n\nOn the first pass, I did not have the step_corr in the preprocessing, but the fit_resamples() generated a warning that stated: “prediction from rank-deficient fit; consider predict(., rankdeficient=”NA”). There were issues with some computations A: x1”.\n\nFirst, I tried step_zv(), since the tidymodel tutorial had stated that if there are dummy variables with low-frequency values that don’t occur in the training data, then it’s possible for some of the downstream functions to generate warnings. That didn’t work.\nFrom other google results, I didn’t find much about the exact warning, but there was a really similar one that apparently can happen when there are variables with really high correlation. Dew point and temperature are very highly correlated, so I decided to use step_cor to address this, and it worked.\n\n\n\nbike_rec_2 &lt;- recipe(rented_bike_count ~ ., data = bike_train) |&gt;\n  update_role(date, new_role = \"ID\") |&gt;\n  step_date(date, features = c(\"dow\")) |&gt;\n  step_mutate(part_of_week = factor(if_else(date_dow %in% c(\"Sat\", \"Sun\"),\n                                        \"Weekend\",\n                                        \"Weekday\"),\n                                levels = c(\"Weekday\", \"Weekend\"))) |&gt;\n  step_rm(date_dow) |&gt;\n  step_normalize(all_numeric(), -all_outcomes()) |&gt;\n  step_dummy(seasons, holiday, part_of_week) |&gt;\n  step_interact(terms = ~ holiday_No.Holiday : starts_with(\"seasons_\") +\n                        temperature : starts_with(\"seasons_\") + \n                        temperature : rainfall) |&gt;\n  #step_zv(all_predictors()) |&gt;\n  step_corr(all_predictors())\n  \nbike_rec_2 |&gt;\n  prep(training = bike_train) |&gt;\n  bake(bike_train)\n\n# A tibble: 263 × 17\n   date       rainfall snowfall temperature humidity wind_speed visibility\n   &lt;date&gt;        &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n 1 2018-09-01   -0.304   -0.236       1.08    0.235     -0.888       0.812\n 2 2018-09-02   -0.304   -0.236       1.04   -0.215     -0.366       1.13 \n 3 2018-09-05   -0.304   -0.236       0.945   0.274      1.40        1.05 \n 4 2018-09-07   -0.175   -0.236       0.802  -0.0574     1.35        0.831\n 5 2018-09-08   -0.304   -0.236       0.762  -0.611     -0.0794      1.11 \n 6 2018-09-09   -0.304   -0.236       0.785  -0.558     -0.844       1.14 \n 7 2018-09-10   -0.304   -0.236       0.869  -0.516     -0.263       1.14 \n 8 2018-09-11   -0.304   -0.236       0.751  -0.659     -0.418       1.14 \n 9 2018-09-12   -0.304   -0.236       0.833  -0.392     -0.690       1.12 \n10 2018-09-13   -0.304   -0.236       0.911   0.308     -0.859       1.11 \n# ℹ 253 more rows\n# ℹ 10 more variables: solar_radiation &lt;dbl&gt;, rented_bike_count &lt;dbl&gt;,\n#   seasons_Spring &lt;dbl&gt;, seasons_Autumn &lt;dbl&gt;, holiday_No.Holiday &lt;dbl&gt;,\n#   part_of_week_Weekend &lt;dbl&gt;, seasons_Spring_x_temperature &lt;dbl&gt;,\n#   seasons_Summer_x_temperature &lt;dbl&gt;, seasons_Autumn_x_temperature &lt;dbl&gt;,\n#   temperature_x_rainfall &lt;dbl&gt;\n\n\nFormula for recipe 2\n\nbike_rec_2 |&gt;\n  prep(training = bike_train) |&gt;\n  formula()\n\nrented_bike_count ~ rainfall + snowfall + temperature + humidity + \n    wind_speed + visibility + solar_radiation + seasons_Spring + \n    seasons_Autumn + holiday_No.Holiday + part_of_week_Weekend + \n    seasons_Spring_x_temperature + seasons_Summer_x_temperature + \n    seasons_Autumn_x_temperature + temperature_x_rainfall\n&lt;environment: 0x000002c2a2380778&gt;\n\n\nRecipe 3\n\nSame transformations and interactions as recipe 2\nAdd quadratic terms for the numeric predictors\n\nNote: On the quadratic step, I initially tried to do step_poly(all_numeric_predictors()), but got an error that said “‘degree’ must be less than number of unique points”. A post on Stack Overflow states this is because there must be columns that don’t have enough unique values. Since the degree is 2, the variables included in step_poly must have at least 3 unique values. All the dummy variables had only 2 unique values. Moving step_poly before step_interact only produced more errors, so I decided to just list out the original predictor variables.\n\nbike_rec_3 &lt;- recipe(rented_bike_count ~ ., data = bike_train) |&gt;\n  update_role(date, new_role = \"ID\") |&gt;\n  step_date(date, features = c(\"dow\")) |&gt;\n  step_mutate(part_of_week = factor(if_else(date_dow %in% c(\"Sat\", \"Sun\"),\n                                        \"Weekend\",\n                                        \"Weekday\"),\n                                levels = c(\"Weekday\", \"Weekend\"))) |&gt;\n  step_rm(date_dow) |&gt;\n  step_normalize(all_numeric(), -all_outcomes()) |&gt;\n  step_dummy(seasons, holiday, part_of_week) |&gt;\n  step_interact(terms = ~ holiday_No.Holiday : starts_with(\"seasons_\") +\n                        temperature : starts_with(\"seasons_\") + \n                        temperature : rainfall) |&gt;\n  # step_poly(all_numeric_predictors())\n  step_poly(rainfall, snowfall, temperature, humidity, wind_speed, visibility,\n            dew_point, solar_radiation) |&gt;\n  step_corr(all_predictors())\n  \nbike_rec_3 |&gt;\n  prep(training = bike_train) |&gt;\n  bake(bike_train)\n\n# A tibble: 263 × 25\n   date       rented_bike_count seasons_Spring seasons_Autumn holiday_No.Holiday\n   &lt;date&gt;                 &lt;dbl&gt;          &lt;dbl&gt;          &lt;dbl&gt;              &lt;dbl&gt;\n 1 2018-09-01             26010              0              1                  1\n 2 2018-09-02             26881              0              1                  1\n 3 2018-09-05             31114              0              1                  1\n 4 2018-09-07             30381              0              1                  1\n 5 2018-09-08             29813              0              1                  1\n 6 2018-09-09             28354              0              1                  1\n 7 2018-09-10             30781              0              1                  1\n 8 2018-09-11             31694              0              1                  1\n 9 2018-09-12             31809              0              1                  1\n10 2018-09-13             30991              0              1                  1\n# ℹ 253 more rows\n# ℹ 20 more variables: part_of_week_Weekend &lt;dbl&gt;,\n#   holiday_No.Holiday_x_seasons_Summer &lt;dbl&gt;,\n#   seasons_Spring_x_temperature &lt;dbl&gt;, seasons_Autumn_x_temperature &lt;dbl&gt;,\n#   temperature_x_rainfall &lt;dbl&gt;, rainfall_poly_1 &lt;dbl&gt;, rainfall_poly_2 &lt;dbl&gt;,\n#   snowfall_poly_1 &lt;dbl&gt;, snowfall_poly_2 &lt;dbl&gt;, temperature_poly_1 &lt;dbl&gt;,\n#   temperature_poly_2 &lt;dbl&gt;, humidity_poly_1 &lt;dbl&gt;, humidity_poly_2 &lt;dbl&gt;, …\n\n\nFormula for recipe 3\n\nbike_rec_3 |&gt;\n  prep(training = bike_train) |&gt;\n  formula()\n\nrented_bike_count ~ seasons_Spring + seasons_Autumn + holiday_No.Holiday + \n    part_of_week_Weekend + holiday_No.Holiday_x_seasons_Summer + \n    seasons_Spring_x_temperature + seasons_Autumn_x_temperature + \n    temperature_x_rainfall + rainfall_poly_1 + rainfall_poly_2 + \n    snowfall_poly_1 + snowfall_poly_2 + temperature_poly_1 + \n    temperature_poly_2 + humidity_poly_1 + humidity_poly_2 + \n    wind_speed_poly_1 + wind_speed_poly_2 + visibility_poly_1 + \n    visibility_poly_2 + dew_point_poly_2 + solar_radiation_poly_1 + \n    solar_radiation_poly_2\n&lt;environment: 0x000002c2a259ca90&gt;\n\n\n\n\n\nUsing a linear model\n\nbike_model &lt;- linear_reg() |&gt;\n  set_engine(\"lm\")\n\n\n\nSet up workflows to use with 10-fold SV to fit a linear model\nRecipe 1\n\nbike_wfl_1 &lt;- workflow() |&gt;\n  add_recipe(bike_rec_1) |&gt;\n  add_model(bike_model)\n\nbike_wfl_1\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_date()\n• step_mutate()\n• step_rm()\n• step_normalize()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n\nRecipe 2\n\nbike_wfl_2 &lt;- workflow() |&gt;\n  add_recipe(bike_rec_2) |&gt;\n  add_model(bike_model)\n\nbike_wfl_2\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n7 Recipe Steps\n\n• step_date()\n• step_mutate()\n• step_rm()\n• step_normalize()\n• step_dummy()\n• step_interact()\n• step_corr()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n\nRecipe 3\n\nbike_wfl_3 &lt;- workflow() |&gt;\n  add_recipe(bike_rec_3) |&gt;\n  add_model(bike_model)\n\nbike_wfl_3\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n8 Recipe Steps\n\n• step_date()\n• step_mutate()\n• step_rm()\n• step_normalize()\n• step_dummy()\n• step_interact()\n• step_poly()\n• step_corr()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n\n\n\n\nHave already set up the 10-fold CV split\nModel 1\n\nbike_CV_fits_1 &lt;- bike_wfl_1 |&gt;\n  fit_resamples(bike_10_fold) \n\nbike_CV_fits_1 |&gt;\n  collect_metrics()\n\n# A tibble: 2 × 6\n  .metric .estimator     mean     n  std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   4090.       10 238.     Preprocessor1_Model1\n2 rsq     standard      0.834    10   0.0186 Preprocessor1_Model1\n\n\nModel 2\n\nbike_CV_fits_2 &lt;- bike_wfl_2 |&gt;\n  fit_resamples(bike_10_fold) \n\nbike_CV_fits_2 |&gt;\n  collect_metrics()\n\n# A tibble: 2 × 6\n  .metric .estimator     mean     n  std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   3806.       10 204.     Preprocessor1_Model1\n2 rsq     standard      0.856    10   0.0158 Preprocessor1_Model1\n\n\nModel 3\n\nbike_CV_fits_3 &lt;- bike_wfl_3 |&gt;\n  fit_resamples(bike_10_fold) \n\nbike_CV_fits_3 |&gt;\n  collect_metrics()\n\n# A tibble: 2 × 6\n  .metric .estimator     mean     n  std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   3375.       10 376.     Preprocessor1_Model1\n2 rsq     standard      0.879    10   0.0322 Preprocessor1_Model1"
  },
  {
    "objectID": "HW9.html#fit-on-entire-training-data",
    "href": "HW9.html#fit-on-entire-training-data",
    "title": "Homework9",
    "section": "",
    "text": "I ran the previous code multiple times, and the RMSE for each model was variable. Each of the models had the lowest RMSE at least once, but I feel that the second model seems to come in lowest pretty often, so that’s the one I went with.\nFit the best model on the entire training set:\n\nbike_wfl_2 |&gt;\n  #fit(bike_train) |&gt;\n  last_fit(bike_split) |&gt;\n  collect_metrics()\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard    4009.    Preprocessor1_Model1\n2 rsq     standard       0.825 Preprocessor1_Model1\n\n\nFit model on the test data\n\n# workflow for 2nd model\n#lm_fit &lt;- fit(bike_wfl_2, bike_train)\n\n# prediction for bikes rented on the test set\nbike_test_res &lt;- bike_wfl_2 |&gt;\n  fit(bike_train) |&gt;\n  predict(new_data = bike_test)\n\nbike_test_res\n\n# A tibble: 90 × 1\n    .pred\n    &lt;dbl&gt;\n 1  9783.\n 2 10129.\n 3 10781.\n 4  2424.\n 5  1746.\n 6  1398.\n 7 11804.\n 8  3347.\n 9  6300.\n10  4898.\n# ℹ 80 more rows\n\n\nCompute RMSE on the test data (confirm model error given above by last_fit)\n\n# add in the truth values\nbike_test_res &lt;- bike_test_res |&gt;\n  bind_cols(bike_test |&gt; ungroup() |&gt; select(rented_bike_count))\n\n# compare to predicted values\nbike_test_res |&gt;\n  rmse(truth = rented_bike_count, estimate = .pred)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       4009."
  },
  {
    "objectID": "HW9.html#final-model",
    "href": "HW9.html#final-model",
    "title": "Homework9",
    "section": "",
    "text": "Fit on the entire training set, get coefficient table\n\nbike_wfl_2 |&gt;\n  #last_fit(bike_split) |&gt;\n  fit(bike_train) |&gt;\n  extract_fit_parsnip() |&gt;\n  tidy()\n\n# A tibble: 16 × 5\n   term                         estimate std.error statistic  p.value\n   &lt;chr&gt;                           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)                   20433.      1521.    13.4   3.01e-31\n 2 rainfall                      -3253.       591.    -5.50  9.39e- 8\n 3 snowfall                       -449.       247.    -1.82  7.06e- 2\n 4 temperature                   11732.      1104.    10.6   5.84e-22\n 5 humidity                       1123.       451.     2.49  1.34e- 2\n 6 wind_speed                       55.3      261.     0.212 8.32e- 1\n 7 visibility                      982.       328.     3.00  3.01e- 3\n 8 solar_radiation                4193.       411.    10.2   1.39e-20\n 9 seasons_Spring                -8539.      1302.    -6.56  3.16e-10\n10 seasons_Autumn                -3219.      1343.    -2.40  1.73e- 2\n11 holiday_No.Holiday             5542.      1148.     4.83  2.41e- 6\n12 part_of_week_Weekend          -2226.       508.    -4.38  1.75e- 5\n13 seasons_Spring_x_temperature  -1618.      1335.    -1.21  2.26e- 1\n14 seasons_Summer_x_temperature -14512.      1968.    -7.37  2.50e-12\n15 seasons_Autumn_x_temperature  -7943.      1299.    -6.11  3.75e- 9\n16 temperature_x_rainfall         1202.       654.     1.84  6.73e- 2\n\n\nReally big coefficients, which might be expected since all numeric predictors were standardized, but the outcome was not. To make sure, I am going to plot the predictions over the original data to make sure it looks okay.\nPlot predictions from the test data against the temperature values in that set, since temperature seems to be the most significant predictor\n\n# take predictions already made, and combine with temperature values\nmlm_points &lt;- bike_test_res[\".pred\"] |&gt;\n  bind_cols(bike_test |&gt; ungroup() |&gt; select(temperature))\n\n# plot original data, with the model line overlay\ng &lt;- ggplot(bike_rollup, aes(x = temperature, y = rented_bike_count)) \ng + geom_point(aes(color = seasons)) +\n  geom_smooth(data = mlm_points, aes(x = temperature, y = .pred))\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nHey, it looks pretty good!"
  },
  {
    "objectID": "HW9.html#best-mlr-model-from-last-week",
    "href": "HW9.html#best-mlr-model-from-last-week",
    "title": "Homework9",
    "section": "Best MLR Model from Last Week",
    "text": "Best MLR Model from Last Week\nModel 3\n\n# prediction for bikes rented on the test set\nbike_test_res &lt;- bike_wfl_3 |&gt;\n  fit(bike_train) |&gt;\n  predict(new_data = bike_test)\n\n# add in the truth values\nbike_test_res &lt;- bike_test_res |&gt;\n  bind_cols(bike_test |&gt; ungroup() |&gt; select(rented_bike_count))\n\n# compare to predicted values - RMSE and MAE\nMLR_metrics &lt;- bind_rows(bike_test_res |&gt; rmse(truth = rented_bike_count, estimate = .pred),\n                         bike_test_res |&gt; mae(truth = rented_bike_count, estimate = .pred)) |&gt;\n  bind_cols(Model = rep(\"MLR Model\", 2)) |&gt;\n  select(Model, everything())\n\nMLR_metrics\n\n# A tibble: 2 × 4\n  Model     .metric .estimator .estimate\n  &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 MLR Model rmse    standard       3536.\n2 MLR Model mae     standard       2549.\n\n\nRedo plot on Model 3 predictions\n\n# take predictions already made, and combine with temperature values\nmlm_points &lt;- bike_test_res[\".pred\"] |&gt;\n  bind_cols(bike_test |&gt; ungroup() |&gt; select(temperature))\n\n# plot original data, with the model line overlay\ng &lt;- ggplot(bike_rollup, aes(x = temperature, y = rented_bike_count)) \ng + geom_point(aes(color = seasons)) +\n  geom_smooth(data = mlm_points, aes(x = temperature, y = .pred))\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nReport coefficients\n\nbike_wfl_3 |&gt;\n  fit(bike_train) |&gt;\n  extract_fit_parsnip() |&gt;\n  tidy()\n\n# A tibble: 24 × 5\n   term                                estimate std.error statistic  p.value\n   &lt;chr&gt;                                  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)                            6633.     1219.      5.44 1.31e- 7\n 2 seasons_Spring                         6560.     1235.      5.31 2.51e- 7\n 3 seasons_Autumn                        11758.     1230.      9.56 1.55e-18\n 4 holiday_No.Holiday                     2687.     1075.      2.50 1.31e- 2\n 5 part_of_week_Weekend                  -2345.      454.     -5.17 4.99e- 7\n 6 holiday_No.Holiday_x_seasons_Summer   18716.     2104.      8.89 1.48e-16\n 7 seasons_Spring_x_temperature          11759.     1183.      9.94 1.04e-19\n 8 seasons_Autumn_x_temperature           7243.     1148.      6.31 1.35e- 9\n 9 temperature_x_rainfall                -1387.      762.     -1.82 7.01e- 2\n10 rainfall_poly_1                      -25525.    10345.     -2.47 1.43e- 2\n# ℹ 14 more rows"
  },
  {
    "objectID": "HW9.html#lasso",
    "href": "HW9.html#lasso",
    "title": "Homework9",
    "section": "LASSO",
    "text": "LASSO\nLASSO model instance\n\nLASSO_spec &lt;- linear_reg(penalty = tune(), mixture = 1) |&gt;\n  set_engine(\"glmnet\")\n\nWorkflow for LASSO\n\nUsing recipe from MLR model 1, because it’s standardized and does not have interactions or quadratics\n\n\nLASSO_wkf &lt;- workflow() |&gt;\n  add_recipe(bike_rec_1) |&gt;\n  add_model(LASSO_spec)\n\nSet up tuning grid for finding parameters\n\nLASSO_grid &lt;- LASSO_wkf |&gt;\n  tune_grid(resamples = bike_10_fold,\n            grid = grid_regular(penalty(), levels = 200))\n\nWarning: package 'glmnet' was built under R version 4.4.2\n\n# lowest RMSE for LASSO\nlowest_rmse_lasso &lt;- LASSO_grid |&gt;\n  select_best(metric = \"rmse\")\n\nlowest_rmse_lasso\n\n# A tibble: 1 × 2\n       penalty .config               \n         &lt;dbl&gt; &lt;chr&gt;                 \n1 0.0000000001 Preprocessor1_Model001\n\n\nFit the best LASSO model on the entire training set\n\nLASSO_final &lt;- LASSO_wkf |&gt;\n  finalize_workflow(lowest_rmse_lasso) |&gt;\n  fit(bike_train)\n\n# Report coefficients\nLASSO_final |&gt;\n  extract_fit_parsnip() |&gt;\n  tidy()\n\n# A tibble: 14 × 3\n   term                 estimate      penalty\n   &lt;chr&gt;                   &lt;dbl&gt;        &lt;dbl&gt;\n 1 (Intercept)           10756.  0.0000000001\n 2 rainfall              -1771.  0.0000000001\n 3 snowfall               -389.  0.0000000001\n 4 temperature               0   0.0000000001\n 5 humidity              -1086.  0.0000000001\n 6 wind_speed             -416.  0.0000000001\n 7 visibility              -53.1 0.0000000001\n 8 dew_point              4485.  0.0000000001\n 9 solar_radiation        4147.  0.0000000001\n10 seasons_Spring         2346.  0.0000000001\n11 seasons_Summer         4134.  0.0000000001\n12 seasons_Autumn         7962.  0.0000000001\n13 holiday_No.Holiday     4259.  0.0000000001\n14 part_of_week_Weekend  -1983.  0.0000000001\n\n\nPredict with LASSO model on the test set\n\n# predictions, plus the truth values\nLASSO_predict &lt;- LASSO_final |&gt;\n  predict(bike_test) |&gt;\n  bind_cols(bike_test |&gt; ungroup() |&gt; select(rented_bike_count))\n\n# compare to predicted values\nLASSO_metrics &lt;- bind_rows(LASSO_predict |&gt; \n                             rmse(truth = rented_bike_count, estimate = .pred),\n                           LASSO_predict |&gt;\n                             mae(truth = rented_bike_count, estimate = .pred)) |&gt;\n  bind_cols(Model = rep(\"LASSO Model\", 2)) |&gt;\n  select(Model, everything())\n\nLASSO_metrics\n\n# A tibble: 2 × 4\n  Model       .metric .estimator .estimate\n  &lt;chr&gt;       &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 LASSO Model rmse    standard       4242.\n2 LASSO Model mae     standard       3227."
  },
  {
    "objectID": "HW9.html#regression-tree-model",
    "href": "HW9.html#regression-tree-model",
    "title": "Homework9",
    "section": "Regression Tree Model",
    "text": "Regression Tree Model\nDefine the model\n\ntree_model &lt;- decision_tree(tree_depth = tune(),\n                            min_n = 20,\n                            cost_complexity = tune()) |&gt;\n  set_engine(\"rpart\") |&gt;\n  set_mode(\"regression\")\n\nDefine workflow, using same recipe as the 3rd MLR model\n\ntree_wkf &lt;- workflow() |&gt;\n  add_recipe(bike_rec_3) |&gt;\n  add_model(tree_model)\n\nDefine grid for the tuning grid\n\ntree_grid &lt;- grid_regular(cost_complexity(),\n                          tree_depth(),\n                          levels = c(10, 5))\n\nPerform tuning\n\n# run the tuning\ntree_fits &lt;- tree_wkf |&gt;\n  tune_grid(resamples = bike_10_fold,\n            grid = tree_grid)\n\n# return the best parameters\ntree_best_params &lt;- tree_fits |&gt;\n  select_best(metric = \"rmse\")\n\ntree_best_params\n\n# A tibble: 1 × 3\n  cost_complexity tree_depth .config              \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;                \n1           0.001          8 Preprocessor1_Model28\n\n\nFit the training set with this best model\n\n# finalize workflow\ntree_final_wkf &lt;- tree_wkf |&gt;\n  finalize_workflow(tree_best_params)\n\n# fit to entire training data\ntree_final_fit &lt;- tree_final_wkf |&gt;\n  last_fit(bike_split)\n\n# extract\ntree_final_model &lt;- extract_workflow(tree_final_fit)\n\n# plot the final fit\ntree_final_model |&gt;\n  extract_fit_engine() |&gt;\n  rpart.plot::rpart.plot(roundint = FALSE)\n\n\n\n\n\n\n\n\nLook at metrics RMSE and MAE on the test data\n\n# predictions, plus the truth values\ntree_predict &lt;- tree_final_wkf |&gt;\n  fit(bike_train) |&gt;\n  predict(bike_test) |&gt;\n  bind_cols(bike_test |&gt; ungroup() |&gt; select(rented_bike_count))\n\n# compare to predicted values\ntree_metrics &lt;- bind_rows(tree_predict |&gt; \n                             rmse(truth = rented_bike_count, estimate = .pred),\n                           tree_predict |&gt;\n                             mae(truth = rented_bike_count, estimate = .pred)) |&gt;\n  bind_cols(Model = rep(\"Regression Tree\", 2)) |&gt;\n  select(Model, everything())\n\ntree_metrics\n\n# A tibble: 2 × 4\n  Model           .metric .estimator .estimate\n  &lt;chr&gt;           &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 Regression Tree rmse    standard       3986.\n2 Regression Tree mae     standard       2849."
  },
  {
    "objectID": "HW9.html#bagged-tree-model",
    "href": "HW9.html#bagged-tree-model",
    "title": "Homework9",
    "section": "Bagged Tree Model",
    "text": "Bagged Tree Model\nDefine model, using regression since the response variable is numeric, continuous\n\nbag_model &lt;- bag_tree(tree_depth = 5, min_n = 10, cost_complexity = tune()) |&gt;\n  set_engine(\"rpart\") |&gt;\n  set_mode(\"regression\")\n\nCreate workflow, using same recipe from MLR model 3\n\nbag_wkf &lt;- workflow() |&gt;\n  add_recipe(bike_rec_3) |&gt;\n  add_model(bag_model)\n\nFit to the CV folds\n\n# fit\nbag_fit &lt;- bag_wkf |&gt;\n  tune_grid(resamples = bike_10_fold,\n            grid = grid_regular(cost_complexity(),\n                                levels = 15))\n\n# get best parameters\nbag_best_params &lt;- bag_fit |&gt;\n  select_best(metric = \"rmse\")\n\nbag_best_params\n\n# A tibble: 1 × 2\n  cost_complexity .config              \n            &lt;dbl&gt; &lt;chr&gt;                \n1     0.000000164 Preprocessor1_Model06\n\n\nRefit the entire training set\n\n# finalize workflow\nbag_final_wkf &lt;- bag_wkf |&gt;\n  finalize_workflow(bag_best_params)\n\n# fit on training set\nbag_final_fit &lt;- bag_final_wkf |&gt;\n  last_fit(bike_split)\n\nbag_final_fit |&gt; collect_metrics()\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard    3269.    Preprocessor1_Model1\n2 rsq     standard       0.885 Preprocessor1_Model1\n\n\nVariable importance plot\n\n# extract\nbag_final_model &lt;- extract_fit_engine(bag_final_fit)\n\n# variable importance plot\nbag_final_model$imp |&gt;\n  mutate(term = factor(term, levels = term)) |&gt;\n  ggplot(aes(x = term, y = value)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip()\n\n\n\n\n\n\n\n\nLook at metrics RMSE and MAE\n\n# predictions, plus the truth values\nbag_predict &lt;- bag_final_wkf |&gt;\n  fit(bike_train) |&gt;\n  predict(bike_test) |&gt;\n  bind_cols(bike_test |&gt; ungroup() |&gt; select(rented_bike_count))\n\n# compare to predicted values\nbag_metrics &lt;- bind_rows(bag_predict |&gt; \n                           rmse(truth = rented_bike_count, estimate = .pred),\n                         bag_predict |&gt;\n                           mae(truth = rented_bike_count, estimate = .pred)) |&gt;\n  bind_cols(Model = rep(\"Bagged Tree\", 2)) |&gt;\n  select(Model, everything())\n\nbag_metrics\n\n# A tibble: 2 × 4\n  Model       .metric .estimator .estimate\n  &lt;chr&gt;       &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 Bagged Tree rmse    standard       3585.\n2 Bagged Tree mae     standard       2668."
  },
  {
    "objectID": "HW9.html#random-forest-model",
    "href": "HW9.html#random-forest-model",
    "title": "Homework9",
    "section": "Random Forest Model",
    "text": "Random Forest Model\nDefine the model\n\nrf_model &lt;- rand_forest(mtry = tune()) |&gt;\n  set_engine(\"ranger\", importance = \"impurity\") |&gt;\n  set_mode(\"regression\")\n\nCreate workflow, using same recipe from MLR model 3\n\nrf_wkf &lt;- workflow() |&gt;\n  add_recipe(bike_rec_3) |&gt;\n  add_model(rf_model)\n\nFit to CV folds\n\nrf_fit &lt;- rf_wkf |&gt;\n  tune_grid(resamples = bike_10_fold)\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\n\nWarning: package 'ranger' was built under R version 4.4.2\n\n\nBest parameters\n\nrf_best_params &lt;- rf_fit |&gt;\n  select_best(metric = \"rmse\")\n\nrf_best_params\n\n# A tibble: 1 × 2\n   mtry .config             \n  &lt;int&gt; &lt;chr&gt;               \n1    15 Preprocessor1_Model6\n\n\nRefit on the entire training set\n\n# finalize workflow\nrf_final_wkf &lt;- rf_wkf |&gt;\n  finalize_workflow(rf_best_params)\n\n# fit to the training set\nrf_final_fit &lt;- rf_final_wkf |&gt;\n  last_fit(bike_split)\n\nrf_final_fit |&gt; collect_metrics()\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard    3030.    Preprocessor1_Model1\n2 rsq     standard       0.905 Preprocessor1_Model1\n\n\nVariable importance plot\n\n# extract model, create vip list\nvip_list &lt;- extract_fit_parsnip(rf_final_fit$.workflow[[1]]) |&gt;\n  vip::vi()\n\n# create vip plot\nvip_list |&gt;\n  mutate(Variable = factor(Variable, levels = Variable)) |&gt;\n  ggplot(aes(x = Variable, y = Importance)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip()\n\n\n\n\n\n\n\n\nLook at metrics RMSE and MAE\n\n# predictions, plus the truth values\nrf_predict &lt;- rf_final_wkf |&gt;\n  fit(bike_train) |&gt;\n  predict(bike_test) |&gt;\n  bind_cols(bike_test |&gt; ungroup() |&gt; select(rented_bike_count))\n\n# compare to predicted values\nrf_metrics &lt;- bind_rows(rf_predict |&gt; \n                          rmse(truth = rented_bike_count, estimate = .pred),\n                        rf_predict |&gt;\n                          mae(truth = rented_bike_count, estimate = .pred)) |&gt;\n  bind_cols(Model = rep(\"Random Forest\", 2)) |&gt;\n  select(Model, everything())\n\nrf_metrics\n\n# A tibble: 2 × 4\n  Model         .metric .estimator .estimate\n  &lt;chr&gt;         &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 Random Forest rmse    standard       3075.\n2 Random Forest mae     standard       2284."
  },
  {
    "objectID": "HW9.html#best-overall-model",
    "href": "HW9.html#best-overall-model",
    "title": "Homework9",
    "section": "Best Overall Model",
    "text": "Best Overall Model\nCompare all metrics to find best overall model\n\nbind_rows(MLR_metrics,\n          LASSO_metrics,\n          tree_metrics,\n          bag_metrics,\n          rf_metrics)\n\n# A tibble: 10 × 4\n   Model           .metric .estimator .estimate\n   &lt;chr&gt;           &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n 1 MLR Model       rmse    standard       3536.\n 2 MLR Model       mae     standard       2549.\n 3 LASSO Model     rmse    standard       4242.\n 4 LASSO Model     mae     standard       3227.\n 5 Regression Tree rmse    standard       3986.\n 6 Regression Tree mae     standard       2849.\n 7 Bagged Tree     rmse    standard       3585.\n 8 Bagged Tree     mae     standard       2668.\n 9 Random Forest   rmse    standard       3075.\n10 Random Forest   mae     standard       2284.\n\n\nRandom Forest model seems to be the overall winner, for both RMSE and MAE"
  },
  {
    "objectID": "HW9.html#fit-to-entire-data-set",
    "href": "HW9.html#fit-to-entire-data-set",
    "title": "Homework9",
    "section": "Fit to Entire Data Set",
    "text": "Fit to Entire Data Set\n\n# predictions, plus the truth values\nrf_predict_final &lt;- rf_final_wkf |&gt;\n  fit(bike_train) |&gt;\n  predict(bike_rollup) |&gt;\n  bind_cols(bike_rollup |&gt; ungroup() |&gt; select(rented_bike_count))\n\n# compare to predicted values\nfinal_metrics &lt;- bind_rows(rf_predict_final |&gt; \n                             rmse(truth = rented_bike_count, estimate = .pred),\n                           rf_predict_final |&gt;\n                             mae(truth = rented_bike_count, estimate = .pred)) |&gt;\n  bind_cols(Model = rep(\"Random Forest Final\", 2)) |&gt;\n  select(Model, everything())\n\nfinal_metrics\n\n# A tibble: 2 × 4\n  Model               .metric .estimator .estimate\n  &lt;chr&gt;               &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 Random Forest Final rmse    standard       1872.\n2 Random Forest Final mae     standard       1279.\n\n\nFinal model performed even better on the full data than on the training!\n\n# add temperature column to predictions on full data set\nrf_points &lt;- rf_predict_final |&gt;\n  bind_cols(bike_rollup[\"temperature\"])\n\n# plot original data, with the random forest predictions as overlay\ng &lt;- ggplot(bike_rollup, aes(x = temperature, y = rented_bike_count)) \ng + geom_point(aes(color = seasons)) +\n  geom_line(data = rf_points, aes(x = temperature, y = .pred))"
  }
]